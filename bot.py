"""
Telegram Bot pentru rezumate de articole
Comenzi: /scurt (250-300), /mediu (500-600), /lung (850-950)
Batch: max 7 linkuri ‚Üí rezumate scurte
Default fƒÉrƒÉ comandƒÉ: lung
"""

import os
import re
import logging
from urllib.parse import urlparse
from telegram import Update, MessageEntity
from telegram.ext import Application, MessageHandler, CommandHandler, filters, ContextTypes
from telegram.constants import ParseMode
import anthropic
import trafilatura

# Configurare logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Chei API din variabile de mediu
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")

# Ini»õializare client Anthropic
client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

# ConfigurƒÉri lungimi
LENGTH_CONFIG = {
    "scurt": {"min": 250, "max": 300, "paragraphs": "1"},
    "mediu": {"min": 500, "max": 600, "paragraphs": "2"},
    "lung": {"min": 850, "max": 950, "paragraphs": "2-3"},
}

MAX_BATCH_LINKS = 7


def get_prompt(length_type: str, has_url: bool) -> str:
    """GenereazƒÉ prompt-ul √Æn func»õie de lungime »ôi tip."""
    config = LENGTH_CONFIG.get(length_type, LENGTH_CONFIG["lung"])
    para_text = "un singur paragraf" if config["paragraphs"] == "1" else f"{config['paragraphs']} paragrafe scurte, separate prin linie goalƒÉ"
    
    base_prompt = f"""E»ôti un editor de »ôtiri. Prime»ôti un {"articol" if has_url else "text"} »ôi trebuie sƒÉ creezi un rezumat √Æn ROM√ÇNƒÇ.

REGULI STRICTE:
1. Rezumatul trebuie sƒÉ aibƒÉ EXACT {config["min"]}-{config["max"]} de caractere (nu cuvinte, caractere!)
2. Scrie rezumatul √Æn {para_text}
3. √éncepe cu un singur emoji relevant pentru subiect (politicƒÉ=üèõÔ∏è, economie=üí∞, tehnologie=üíª, rƒÉzboi/conflict=‚öîÔ∏è, UE=üá™üá∫, Moldova=üá≤üá©, Rom√¢nia=üá∑üá¥, Rusia=üá∑üá∫, SUA=üá∫üá∏, sport=‚öΩ, sƒÉnƒÉtate=üè•, mediu=üåç, etc.)
4. NU pune bold, italic sau alte formatƒÉri
5. NU pune link-uri √Æn text
6. Scrie la persoana a 3-a, stil jurnalistic neutru
7. DacƒÉ {"articolul" if has_url else "textul"} e √Æn altƒÉ limbƒÉ, traduci rezumatul √Æn rom√¢nƒÉ
{"8. MarcheazƒÉ UN SINGUR cuv√¢nt cheie cu acolade, exemplu: {{atacat}} - acesta va deveni link" if has_url else ""}

{"ARTICOL" if has_url else "TEXT"}:
{{content}}

RƒÉspunde DOAR cu rezumatul (emoji + text{"cu un cuv√¢nt √Æn acolade" if has_url else ""}), nimic altceva."""
    
    return base_prompt


def clean_telegram_footer(text: str) -> str:
    """CurƒÉ»õƒÉ footerele de Telegram."""
    footer_patterns = [
        r'–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ .*$', r'–ü–æ–¥–ø–∏—à–∏—Å—å –Ω–∞ .*$', r'–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å.*$',
        r'–ü—Ä–∏—Å–ª–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç.*$', r'–ù–∞—à –∫–∞–Ω–∞–ª.*$', r'–ß–∏—Ç–∞—Ç—å –¥–∞–ª–µ–µ.*$', r'–ò—Å—Ç–æ—á–Ω–∏–∫.*$',
        r'Subscribe to .*$', r'Follow us.*$', r'Join our.*$', r'Send content.*$',
        r'AboneazƒÉ-te la .*$', r'UrmƒÉre»ôte-ne.*$', r'Canalul nostru.*$', r'\s*\|\s*$',
    ]
    
    lines = text.split('\n')
    cleaned_lines = []
    
    for line in lines:
        is_footer = False
        for pattern in footer_patterns:
            if re.search(pattern, line, re.IGNORECASE):
                is_footer = True
                break
        if re.match(r'^\s*https?://t\.me/\S*\s*$', line):
            is_footer = True
        if re.match(r'^[\s|/]*https?://\S+[\s|/]*$', line):
            is_footer = True
        if not is_footer:
            cleaned_lines.append(line)
    
    cleaned_text = '\n'.join(cleaned_lines)
    cleaned_text = re.sub(r'\s*\(https?://t\.me/[^)]+\)', '', cleaned_text)
    cleaned_text = re.sub(r'\n{3,}', '\n\n', cleaned_text)
    return cleaned_text.strip()


def extract_urls_from_entities(message) -> list:
    """Extrage URL-uri din mesaj."""
    urls = []
    text = message.text or message.caption or ""
    entities = message.entities or message.caption_entities or []
    
    for entity in entities:
        if entity.type == MessageEntity.URL:
            urls.append(text[entity.offset:entity.offset + entity.length])
        elif entity.type == MessageEntity.TEXT_LINK:
            urls.append(entity.url)
    
    text_urls = re.findall(r'https?://[^\s<>"{}|\\^`\[\]]+', text)
    urls.extend(text_urls)
    
    return list(dict.fromkeys(urls))  # Unique, pƒÉstreazƒÉ ordinea


def filter_article_urls(urls: list) -> list:
    """FiltreazƒÉ doar URL-uri cƒÉtre articole."""
    ignore_domains = ['t.me', 'telegram.me', 'twitter.com', 'x.com', 
                      'facebook.com', 'instagram.com', 'tiktok.com', 'youtube.com', 'youtu.be']
    
    article_urls = []
    for url in urls:
        try:
            domain = urlparse(url).netloc.lower()
            if not any(ignore in domain for ignore in ignore_domains):
                article_urls.append(url)
        except:
            pass
    return article_urls


def format_summary_html(summary: str, url: str = None) -> str:
    """FormateazƒÉ rezumatul cu HTML."""
    summary = summary.replace("**", "").replace("*", "").replace("__", "")
    summary = summary.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
    
    # SeparƒÉ emoji
    emoji_part = ""
    text_part = summary
    if len(summary) > 0 and not summary[0].isalnum() and summary[0] not in '([{':
        i = 0
        while i < len(summary) and not summary[i].isalnum():
            i += 1
        emoji_part = summary[:i].rstrip()
        text_part = summary[i:].lstrip()
    
    # GƒÉse»ôte cuv√¢ntul marcat
    link_word = None
    link_word_match = re.search(r'\{+([^}]+)\}+', text_part)
    if link_word_match:
        link_word = link_word_match.group(1)
        text_part = text_part[:link_word_match.start()] + link_word + text_part[link_word_match.end():]
    
    # ProceseazƒÉ paragrafe
    paragraphs = re.split(r'\n\s*\n|\n', text_part)
    paragraphs = [p.strip() for p in paragraphs if p.strip()]
    
    formatted_paragraphs = []
    for para_idx, paragraph in enumerate(paragraphs):
        words = paragraph.split()
        result_words = []
        
        for word_idx, word in enumerate(words):
            is_link_word = link_word and link_word in word
            
            if word_idx < 3:
                if is_link_word and url:
                    word_with_link = word.replace(link_word, f'<a href="{url}">{link_word}</a>')
                    if word_idx == 0:
                        result_words.append(f"<b>{word_with_link}")
                    elif word_idx == 2:
                        result_words.append(f"{word_with_link}</b>")
                    else:
                        result_words.append(word_with_link)
                    link_word = None
                else:
                    if word_idx == 0:
                        result_words.append(f"<b>{word}")
                    elif word_idx == 2:
                        result_words.append(f"{word}</b>")
                    else:
                        result_words.append(word)
            else:
                if is_link_word and url:
                    result_words.append(word.replace(link_word, f'<a href="{url}">{link_word}</a>'))
                    link_word = None
                else:
                    result_words.append(word)
        
        if len(words) > 0 and len(words) < 3:
            result_words[-1] = result_words[-1] + "</b>"
        
        formatted_para = " ".join(result_words)
        if para_idx > 0:
            formatted_para = "(...) " + formatted_para
        formatted_paragraphs.append(formatted_para)
    
    formatted_text = "\n\n".join(formatted_paragraphs)
    return f"{emoji_part} {formatted_text}" if emoji_part else formatted_text


def fetch_article_content(url: str) -> str | None:
    """DescarcƒÉ »ôi extrage con»õinutul unui articol."""
    try:
        # Metoda 1: Trafilatura standard
        downloaded = trafilatura.fetch_url(url)
        if downloaded:
            content = trafilatura.extract(downloaded, include_comments=False, include_tables=False, no_fallback=False)
            if content and len(content) > 100:
                return content
        
        # Metoda 2: Fallback Jina AI - pentru ORICE site care e»ôueazƒÉ
        logger.info(f"Trafilatura e»ôuat, √Æncerc Jina AI pentru: {url[:60]}")
        try:
            import httpx
            jina_url = f"https://r.jina.ai/{url}"
            response = httpx.get(jina_url, timeout=20.0, follow_redirects=True)
            if response.status_code == 200:
                content = response.text
                # CurƒÉ»õƒÉ markdown headers »ôi formatare excesivƒÉ
                content = re.sub(r'^#+\s+', '', content, flags=re.MULTILINE)
                content = re.sub(r'\n{3,}', '\n\n', content)
                if len(content) > 200:
                    logger.info(f"‚úì Jina AI SUCCESS: {len(content)} caractere")
                    return content
                else:
                    logger.warning(f"Jina AI: con»õinut prea scurt ({len(content)} char)")
            else:
                logger.warning(f"Jina AI HTTP {response.status_code}")
        except Exception as e:
            logger.warning(f"Jina AI e»ôuat: {type(e).__name__}: {str(e)[:50]}")
        
    except Exception as e:
        logger.error(f"Eroare extragere: {e}")
    
    return None


def generate_summary(content: str, url: str = None, length_type: str = "lung") -> tuple:
    """GenereazƒÉ rezumat. ReturneazƒÉ (rezumat, eroare)."""
    try:
        prompt_template = get_prompt(length_type, has_url=bool(url))
        prompt = prompt_template.format(content=content[:15000])
        
        message = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=1500,
            messages=[{"role": "user", "content": prompt}]
        )
        
        raw_summary = message.content[0].text
        formatted = format_summary_html(raw_summary, url)
        return formatted, None
        
    except anthropic.AuthenticationError:
        return None, "Cheie API invalidƒÉ"
    except anthropic.RateLimitError:
        return None, "Prea multe cereri"
    except anthropic.APIError as e:
        return None, f"Eroare API: {str(e)[:100]}"
    except Exception as e:
        return None, f"{type(e).__name__}: {str(e)[:100]}"


async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handler pentru /start."""
    welcome = (
        "üëã Salut! Sunt botul pentru rezumate de »ôtiri.\n\n"
        "üìù <b>Comenzi:</b>\n"
        "‚Ä¢ <code>/scurt link</code> ‚Üí 250-300 caractere\n"
        "‚Ä¢ <code>/mediu link</code> ‚Üí 500-600 caractere\n"
        "‚Ä¢ <code>/lung link</code> ‚Üí 850-950 caractere\n"
        "‚Ä¢ Link fƒÉrƒÉ comandƒÉ ‚Üí lung (default)\n\n"
        "üì¶ <b>Batch:</b> Trimite p√¢nƒÉ la 7 linkuri (pe linii separate) ‚Üí rezumate scurte\n\n"
        "üöÄ Trimite primul link!"
    )
    await update.message.reply_text(welcome, parse_mode=ParseMode.HTML)


async def process_single_article(url: str, length_type: str) -> str:
    """ProceseazƒÉ un singur articol »ôi returneazƒÉ rezumatul."""
    content = fetch_article_content(url)
    if not content:
        return f"‚ùå Nu am putut extrage: {url[:50]}..."
    
    summary, error = generate_summary(content, url, length_type)
    if not summary:
        return f"‚ùå Eroare pentru {url[:50]}...: {error}"
    
    return summary


def get_relevant_emoji(text: str) -> list:
    """DeterminƒÉ lista de emoji-uri relevante pe baza con»õinutului (√Æn ordinea prioritƒÉ»õii)."""
    text_lower = text.lower()
    relevant_emojis = []
    
    # PoliticƒÉ / Guvern
    if any(word in text_lower for word in ['parlament', 'guvern', 'ministru', 'deputat', 'legislativ', 'politic', 'alegeri', 'vot', 'lege', 'pre≈üedinte', 'premier']):
        relevant_emojis.append('üèõÔ∏è')
    
    # Moldova
    if any(word in text_lower for word in ['moldova', 'chi»ôinƒÉu', 'chisinau', 'maia sandu', 'pas ', 'psrm']):
        relevant_emojis.append('üá≤üá©')
    
    # Rom√¢nia
    if any(word in text_lower for word in ['rom√¢nia', 'romania', 'bucure≈üti', 'bucuresti', 'iohannis', 'rom√¢n']):
        relevant_emojis.append('üá∑üá¥')
    
    # Ucraina
    if any(word in text_lower for word in ['ucraina', 'kiev', 'ucrainean', 'zelensky']):
        relevant_emojis.append('üá∫üá¶')
    
    # Polonia
    if any(word in text_lower for word in ['polonia', 'var»ôovia', 'polonez', 'warszawa']):
        relevant_emojis.append('üáµüá±')
    
    # Turcia
    if any(word in text_lower for word in ['turcia', 'ankara', 'istanbul', 'turc', 'erdogan']):
        relevant_emojis.append('üáπüá∑')
    
    # UE
    if any(word in text_lower for word in ['uniunea europeanƒÉ', 'uniunea europeana', 'bruxelles', 'comisia europeanƒÉ', 'ue ', 'european', 'ambasador ue']):
        relevant_emojis.append('üá™üá∫')
    
    # Rusia
    if any(word in text_lower for word in ['rusia', 'kremlin', 'moscova', 'putin', 'rus']):
        relevant_emojis.append('üá∑üá∫')
    
    # SUA / America
    if any(word in text_lower for word in ['sua', 'statele unite', 'washington', 'america', 'trump', 'biden', 'american']):
        relevant_emojis.append('üá∫üá∏')
    
    # Canada
    if any(word in text_lower for word in ['canada', 'canadian', 'ottawa', 'trudeau']):
        relevant_emojis.append('üá®üá¶')
    
    # Fran»õa
    if any(word in text_lower for word in ['fran≈£a', 'franta', 'paris', 'macron', 'francez']):
        relevant_emojis.append('üá´üá∑')
    
    # Spania
    if any(word in text_lower for word in ['spania', 'madrid', 'spaniol', 'espanyol']):
        relevant_emojis.append('üá™üá∏')
    
    # Italia
    if any(word in text_lower for word in ['italia', 'italian', 'roma', 'milan']):
        relevant_emojis.append('üáÆüáπ')
    
    # Germania
    if any(word in text_lower for word in ['germania', 'berlin', 'german']):
        relevant_emojis.append('üá©üá™')
    
    # Marea Britanie
    if any(word in text_lower for word in ['marea britanie', 'anglia', 'londra', 'britanic']):
        relevant_emojis.append('üá¨üáß')
    
    # Australia
    if any(word in text_lower for word in ['australia', 'australian', 'sydney']):
        relevant_emojis.append('üá¶üá∫')
    
    # India
    if any(word in text_lower for word in ['india', 'indian', 'delhi', 'mumbai']):
        relevant_emojis.append('üáÆüá≥')
    
    # Brazilia
    if any(word in text_lower for word in ['brazilia', 'brazilian', 'brasilia']):
        relevant_emojis.append('üáßüá∑')
    
    # China
    if any(word in text_lower for word in ['china', 'chinei', 'beijing', 'chinezesc']):
        relevant_emojis.append('üá®üá≥')
    
    # Japonia
    if any(word in text_lower for word in ['japonia', 'japonez', 'tokyo']):
        relevant_emojis.append('üáØüáµ')
    
    # RƒÉzboi / Conflict / ArmatƒÉ
    if any(word in text_lower for word in ['rƒÉzboi', 'razboi', 'conflict', 'militar', 'armatƒÉ', 'armata', 'atac', 'arme', 'solda≈£', 'soldat']):
        relevant_emojis.append('‚öîÔ∏è')
    
    # Securitate / ApƒÉrare
    if any(word in text_lower for word in ['securitate', 'apƒÉrare', 'aparare', 'protec≈£ie', 'protectie', 'secret', 'spionaj', 'informa»õii', 'informatii clasificate']):
        relevant_emojis.append('üõ°Ô∏è')
    
    # Justi»õie / Lege
    if any(word in text_lower for word in ['judecƒÉtor', 'judecator', 'tribunal', 'condamnat', 'sentin≈£ƒÉ', 'sentinta', 'proces', 'procuror', 'avocat', 'instan≈£ƒÉ', 'instanta', 'penal', 'juridic']):
        relevant_emojis.append('‚öñÔ∏è')
    
    # Economie / Bani / Business / BancƒÉ
    if any(word in text_lower for word in ['economie', 'bancƒÉ', 'banca', 'bani', 'pre≈£', 'pret', 'dolar', 'euro', 'infla»õie', 'inflatie', 'salariu', 'buget', 'fiscal', 'financiar', 'investi≈£ie']):
        relevant_emojis.append('üí∞')
    
    # BancƒÉ specific
    if any(word in text_lower for word in ['bancƒÉ', 'banca', 'bnm', 'banca na≈£ionalƒÉ', 'banca nationala', 'credit', '√Æmprumut', 'imprumut', 'depozit']):
        relevant_emojis.append('üè¶')
    
    # Tehnologie / Digital / Crypto
    if any(word in text_lower for word in ['tehnologie', 'tehnologic', 'digital', 'internet', 'computer', 'software', 'ai ', 'inteligen»õƒÉ artificialƒÉ', 'crypto', 'blockchain', 'bitcoin']):
        relevant_emojis.append('üíª')
    
    # Internet / Online / Web
    if any(word in text_lower for word in ['internet', 'online', 'web', 'site', 'portal', 'platform', 're≈£ea', 'retea socialƒÉ']):
        relevant_emojis.append('üåê')
    
    # Mobile / Telefon / App
    if any(word in text_lower for word in ['telefon', 'mobil', 'smartphone', 'aplica≈£ie', 'aplicatie', 'app']):
        relevant_emojis.append('üì±')
    
    # SƒÉnƒÉtate / Medical
    if any(word in text_lower for word in ['sƒÉnƒÉtate', 'sanatate', 'medical', 'spital', 'doctor', 'pacient', 'boalƒÉ', 'boala', 'virus', 'vaccin', 'tratament']):
        relevant_emojis.append('üè•')
    
    # Sport
    if any(word in text_lower for word in ['fotbal', 'meci', 'echipƒÉ', 'echipa', 'campionat', 'jucƒÉtor', 'jucator', 'sport', 'olimpic', 'antrenor']):
        relevant_emojis.append('‚öΩ')
    
    # Mediu / NaturƒÉ / ClimƒÉ
    if any(word in text_lower for word in ['mediu', 'climƒÉ', 'clima', 'poluare', 'ecologic', 'naturƒÉ', 'natura', 'pƒÉdure', 'padure', 'meteo', 'vreme']):
        relevant_emojis.append('üåç')
    
    # Educa»õie / Universitate / »òcoalƒÉ
    if any(word in text_lower for word in ['educa≈£ie', 'educatie', '≈ücoalƒÉ', 'scoala', 'universitate', 'student', 'profesor', 'elev', 'grƒÉdini»õƒÉ', 'gradinita']):
        relevant_emojis.append('üìö')
    
    # Universitate specific
    if any(word in text_lower for word in ['universitate', 'student', 'rector', 'facultate', 'academic']):
        relevant_emojis.append('üéì')
    
    # Transport / Auto
    if any(word in text_lower for word in ['ma≈üinƒÉ', 'masina', 'auto', 'trafic', '≈üofer', 'sofer', 'drum', 'accident', 'transport']):
        relevant_emojis.append('üöó')
    
    # Avia»õie / CƒÉlƒÉtorii / Turism
    if any(word in text_lower for word in ['avion', 'zbor', 'aeroport', 'cƒÉlƒÉtorie', 'calatorie', 'turism', 'turist']):
        relevant_emojis.append('‚úàÔ∏è')
    
    # Energie / Electric
    if any(word in text_lower for word in ['energie', 'electric', 'gaz', 'petrol', 'combustibil', 'centralƒÉ', 'centrala', 'curent']):
        relevant_emojis.append('‚ö°')
    
    # Industrie / FabricƒÉ / Produc»õie
    if any(word in text_lower for word in ['industrie', 'fabricƒÉ', 'fabrica', 'produc≈£ie', 'productie', 'industrial', 'uzinƒÉ', 'uzina']):
        relevant_emojis.append('üè≠')
    
    # DacƒÉ nu s-a gƒÉsit nimic specific, returneazƒÉ emoji-uri generale
    if not relevant_emojis:
        relevant_emojis = ['üì∞', 'üî•', '‚ú®', 'üìä', 'üéØ', '‚ö†Ô∏è', 'üöÄ']
    
    return relevant_emojis


def ensure_emoji_in_summaries(summaries: list) -> list:
    """AsigurƒÉ cƒÉ fiecare rezumat are emoji UNIC »ôi RELEVANT la √Ænceput."""
    fixed_summaries = []
    used_emojis = set()  # Track emoji-uri deja folosite
    
    # Lista completƒÉ de emoji-uri disponibile ca fallback
    all_emojis = ['üèõÔ∏è', 'üá≤üá©', 'üá∑üá¥', 'üá∫üá¶', 'üáµüá±', 'üáπüá∑', 'üá™üá∫', 'üá∑üá∫', 'üá∫üá∏', 'üá®üá¶',
                  'üá´üá∑', 'üá™üá∏', 'üáÆüáπ', 'üá©üá™', 'üá¨üáß', 'üá¶üá∫', 'üáÆüá≥', 'üáßüá∑', 'üá®üá≥', 'üáØüáµ',
                  '‚öîÔ∏è', 'üõ°Ô∏è', '‚öñÔ∏è', 'üí∞', 'üè¶', 'üíª', 'üåê', 'üì±', 'üè•', '‚öΩ', 'üåç',
                  'üìö', 'üéì', 'üöó', '‚úàÔ∏è', '‚ö°', 'üè≠', 'üì∞', 'üöÄ', 'üî•', '‚ú®', 'üìä', 'üéØ', '‚ö†Ô∏è']
    
    for idx, summary in enumerate(summaries):
        # Skip mesaje de eroare
        if summary.startswith('‚ùå'):
            fixed_summaries.append(summary)
            continue
        
        # VerificƒÉ dacƒÉ are deja emoji
        current_emoji = None
        for emoji in all_emojis:
            if summary.startswith(emoji):
                current_emoji = emoji
                break
        
        if current_emoji:
            # Are emoji - verificƒÉ dacƒÉ e duplicat
            if current_emoji in used_emojis:
                # DUPLICAT! GƒÉse»ôte alt emoji RELEVANT
                logger.info(f"Summary #{idx}: duplicate emoji {current_emoji}, finding relevant replacement...")
                
                # Ob»õine lista de emoji-uri relevante pentru con»õinut
                relevant_emojis = get_relevant_emoji(summary)
                
                # Alege primul emoji relevant care NU a fost folosit
                chosen_emoji = None
                for emoji in relevant_emojis:
                    if emoji not in used_emojis:
                        chosen_emoji = emoji
                        break
                
                # DacƒÉ to»õi emoji-ii relevan»õi sunt folosi»õi, alege orice altul disponibil
                if not chosen_emoji:
                    for emoji in all_emojis:
                        if emoji not in used_emojis:
                            chosen_emoji = emoji
                            break
                
                # DacƒÉ nu mai sunt emoji-uri disponibile (batch >30), folose»ôte primul relevant
                if not chosen_emoji:
                    chosen_emoji = relevant_emojis[0] if relevant_emojis else 'üì∞'
                
                # √énlocuie»ôte emoji-ul vechi cu cel nou
                summary_without_emoji = summary[len(current_emoji):].lstrip()
                fixed_summaries.append(f"{chosen_emoji} {summary_without_emoji}")
                used_emojis.add(chosen_emoji)
                logger.info(f"  ‚Üí Replaced {current_emoji} with relevant {chosen_emoji}")
            else:
                # Emoji unic, pƒÉstreazƒÉ-l
                fixed_summaries.append(summary)
                used_emojis.add(current_emoji)
                logger.info(f"Summary #{idx}: keeping unique emoji {current_emoji}")
        else:
            # Nu are emoji - adaugƒÉ unul RELEVANT care nu a fost folosit
            logger.info(f"Summary #{idx}: no emoji, finding relevant one...")
            
            # Ob»õine lista de emoji-uri relevante
            relevant_emojis = get_relevant_emoji(summary)
            
            # Alege primul emoji relevant care NU a fost folosit
            chosen_emoji = None
            for emoji in relevant_emojis:
                if emoji not in used_emojis:
                    chosen_emoji = emoji
                    break
            
            # DacƒÉ to»õi emoji-ii relevan»õi sunt folosi»õi, alege orice altul disponibil
            if not chosen_emoji:
                for emoji in all_emojis:
                    if emoji not in used_emojis:
                        chosen_emoji = emoji
                        break
            
            # DacƒÉ nu mai sunt emoji-uri disponibile, folose»ôte primul relevant
            if not chosen_emoji:
                chosen_emoji = relevant_emojis[0] if relevant_emojis else 'üì∞'
            
            logger.info(f"  ‚Üí Adding relevant {chosen_emoji}")
            fixed_summaries.append(f"{chosen_emoji} {summary}")
            used_emojis.add(chosen_emoji)
    
    return fixed_summaries

async def handle_length_command(update: Update, context: ContextTypes.DEFAULT_TYPE, length_type: str):
    """Handler comun pentru comenzile /scurt, /mediu, /lung."""
    text = update.message.text or ""
    
    # Extrage linkurile din mesaj (dupƒÉ comandƒÉ)
    urls = re.findall(r'https?://[^\s<>"{}|\\^`\[\]]+', text)
    article_urls = filter_article_urls(urls)
    
    if not article_urls:
        await update.message.reply_text(f"‚ùå Folose»ôte: /{length_type} https://link-articol.com")
        return
    
    processing_msg = await update.message.reply_text("‚è≥ Procesez...")
    
    # Un singur link
    if len(article_urls) == 1:
        summary = await process_single_article(article_urls[0], length_type)
        await processing_msg.edit_text(summary, parse_mode=ParseMode.HTML)
    else:
        # Batch - max 7, folose»ôte tipul specificat
        urls_to_process = article_urls[:MAX_BATCH_LINKS]
        summaries = []
        
        for i, url in enumerate(urls_to_process):
            await processing_msg.edit_text(f"‚è≥ Procesez {i+1}/{len(urls_to_process)}...")
            summary = await process_single_article(url, length_type)
            summaries.append(summary)
        
        # AsigurƒÉ cƒÉ toate rezumatele au emoji-uri UNICE (fƒÉrƒÉ duplicate)
        summaries = ensure_emoji_in_summaries(summaries)
        
        final_text = "\n\n".join(summaries)
        
        # Telegram are limitƒÉ de 4096 caractere
        if len(final_text) > 4000:
            final_text = final_text[:4000] + "\n\n‚ö†Ô∏è Textul a fost trunchiat."
        
        await processing_msg.edit_text(final_text, parse_mode=ParseMode.HTML)


async def scurt_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await handle_length_command(update, context, "scurt")

async def mediu_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await handle_length_command(update, context, "mediu")

async def lung_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await handle_length_command(update, context, "lung")


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handler pentru mesaje fƒÉrƒÉ comandƒÉ."""
    text = update.message.text or update.message.caption or ""
    
    if not text.strip():
        await update.message.reply_text("‚ùå Mesajul e gol.")
        return
    
    all_urls = extract_urls_from_entities(update.message)
    article_urls = filter_article_urls(all_urls)
    
    if not article_urls:
        # Text fƒÉrƒÉ URL - rezumat lung din text
        cleaned_text = clean_telegram_footer(text)
        if len(cleaned_text) < 50:
            await update.message.reply_text("‚ùå Textul e prea scurt.")
            return
        
        processing_msg = await update.message.reply_text("‚è≥ Procesez textul...")
        summary, error = generate_summary(cleaned_text, url=None, length_type="lung")
        
        if not summary:
            await processing_msg.edit_text(f"‚ùå Eroare: {error}")
            return
        
        await processing_msg.edit_text(summary, parse_mode=ParseMode.HTML)
        return
    
    processing_msg = await update.message.reply_text("‚è≥ Procesez...")
    
    # Un singur link - rezumat LUNG (default)
    if len(article_urls) == 1:
        summary = await process_single_article(article_urls[0], "lung")
        await processing_msg.edit_text(summary, parse_mode=ParseMode.HTML)
    else:
        # Batch - max 7, rezumate SCURTE
        urls_to_process = article_urls[:MAX_BATCH_LINKS]
        summaries = []
        
        for i, url in enumerate(urls_to_process):
            await processing_msg.edit_text(f"‚è≥ Procesez {i+1}/{len(urls_to_process)}...")
            summary = await process_single_article(url, "scurt")
            summaries.append(summary)
        
        # AsigurƒÉ cƒÉ toate rezumatele au emoji-uri UNICE (fƒÉrƒÉ duplicate)
        summaries = ensure_emoji_in_summaries(summaries)
        
        final_text = "\n\n".join(summaries)
        
        if len(final_text) > 4000:
            final_text = final_text[:4000] + "\n\n‚ö†Ô∏è Textul a fost trunchiat."
        
        if len(article_urls) > MAX_BATCH_LINKS:
            final_text += f"\n\n‚ö†Ô∏è Am procesat doar primele {MAX_BATCH_LINKS} linkuri."
        
        await processing_msg.edit_text(final_text, parse_mode=ParseMode.HTML)



def main():
    """Porne»ôte botul."""
    if not TELEGRAM_TOKEN:
        raise ValueError("TELEGRAM_TOKEN nu e setat!")
    if not ANTHROPIC_API_KEY:
        raise ValueError("ANTHROPIC_API_KEY nu e setat!")
    
    application = Application.builder().token(TELEGRAM_TOKEN).build()
    
    # Comenzi
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("scurt", scurt_command))
    application.add_handler(CommandHandler("mediu", mediu_command))
    application.add_handler(CommandHandler("lung", lung_command))
    
    # Mesaje text
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(MessageHandler(filters.FORWARDED, handle_message))
    
    logger.info("Botul porne»ôte...")
    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    main()
