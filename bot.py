"""
Telegram Bot pentru rezumate de articole
Comenzi: /scurt (250-300), /mediu (500-600), /lung (850-950)
Batch: max 7 linkuri â†’ rezumate scurte
Default fÄƒrÄƒ comandÄƒ: lung
"""

import os
import re
import logging
from urllib.parse import urlparse
from telegram import Update, MessageEntity
from telegram.ext import Application, MessageHandler, CommandHandler, filters, ContextTypes
from telegram.constants import ParseMode
import anthropic
import trafilatura

# Configurare logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Chei API din variabile de mediu
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")

# IniÈ›ializare client Anthropic
client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

# ConfigurÄƒri lungimi
LENGTH_CONFIG = {
    "scurt": {"min": 250, "max": 300, "paragraphs": "1"},
    "mediu": {"min": 500, "max": 600, "paragraphs": "2"},
    "lung": {"min": 850, "max": 950, "paragraphs": "2-3"},
}

MAX_BATCH_LINKS = 7


def get_prompt(length_type: str, has_url: bool) -> str:
    """GenereazÄƒ prompt-ul Ã®n funcÈ›ie de lungime È™i tip."""
    config = LENGTH_CONFIG.get(length_type, LENGTH_CONFIG["lung"])
    para_text = "un singur paragraf" if config["paragraphs"] == "1" else f"{config['paragraphs']} paragrafe scurte, separate prin linie goalÄƒ"
    
    base_prompt = f"""EÈ™ti un editor de È™tiri. PrimeÈ™ti un {"articol" if has_url else "text"} È™i trebuie sÄƒ creezi un rezumat Ã®n ROMÃ‚NÄ‚.

REGULI STRICTE:
1. Rezumatul trebuie sÄƒ aibÄƒ EXACT {config["min"]}-{config["max"]} de caractere (nu cuvinte, caractere!)
2. Scrie rezumatul Ã®n {para_text}
3. Ãncepe cu un singur emoji relevant pentru subiect (politicÄƒ=ğŸ›ï¸, economie=ğŸ’°, tehnologie=ğŸ’», rÄƒzboi/conflict=âš”ï¸, UE=ğŸ‡ªğŸ‡º, Moldova=ğŸ‡²ğŸ‡©, RomÃ¢nia=ğŸ‡·ğŸ‡´, Rusia=ğŸ‡·ğŸ‡º, SUA=ğŸ‡ºğŸ‡¸, sport=âš½, sÄƒnÄƒtate=ğŸ¥, mediu=ğŸŒ, etc.)
4. NU pune bold, italic sau alte formatÄƒri
5. NU pune link-uri Ã®n text
6. Scrie la persoana a 3-a, stil jurnalistic neutru
7. DacÄƒ {"articolul" if has_url else "textul"} e Ã®n altÄƒ limbÄƒ, traduci rezumatul Ã®n romÃ¢nÄƒ
{"8. MarcheazÄƒ UN SINGUR cuvÃ¢nt cheie cu acolade, exemplu: {{atacat}} - acesta va deveni link" if has_url else ""}

{"ARTICOL" if has_url else "TEXT"}:
{{content}}

RÄƒspunde DOAR cu rezumatul (emoji + text{"cu un cuvÃ¢nt Ã®n acolade" if has_url else ""}), nimic altceva."""
    
    return base_prompt


def clean_telegram_footer(text: str) -> str:
    """CurÄƒÈ›Äƒ footerele de Telegram."""
    footer_patterns = [
        r'ĞŸĞ¾Ğ´Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒÑÑ Ğ½Ğ° .*$', r'ĞŸĞ¾Ğ´Ğ¿Ğ¸ÑˆĞ¸ÑÑŒ Ğ½Ğ° .*$', r'ĞŸĞ¾Ğ´Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°Ğ¹Ñ‚ĞµÑÑŒ.*$',
        r'ĞŸÑ€Ğ¸ÑĞ»Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚.*$', r'ĞĞ°Ñˆ ĞºĞ°Ğ½Ğ°Ğ».*$', r'Ğ§Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ»ĞµĞµ.*$', r'Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº.*$',
        r'Subscribe to .*$', r'Follow us.*$', r'Join our.*$', r'Send content.*$',
        r'AboneazÄƒ-te la .*$', r'UrmÄƒreÈ™te-ne.*$', r'Canalul nostru.*$', r'\s*\|\s*$',
    ]
    
    lines = text.split('\n')
    cleaned_lines = []
    
    for line in lines:
        is_footer = False
        for pattern in footer_patterns:
            if re.search(pattern, line, re.IGNORECASE):
                is_footer = True
                break
        if re.match(r'^\s*https?://t\.me/\S*\s*$', line):
            is_footer = True
        if re.match(r'^[\s|/]*https?://\S+[\s|/]*$', line):
            is_footer = True
        if not is_footer:
            cleaned_lines.append(line)
    
    cleaned_text = '\n'.join(cleaned_lines)
    cleaned_text = re.sub(r'\s*\(https?://t\.me/[^)]+\)', '', cleaned_text)
    cleaned_text = re.sub(r'\n{3,}', '\n\n', cleaned_text)
    return cleaned_text.strip()


def extract_urls_from_entities(message) -> list:
    """Extrage URL-uri din mesaj."""
    urls = []
    text = message.text or message.caption or ""
    entities = message.entities or message.caption_entities or []
    
    for entity in entities:
        if entity.type == MessageEntity.URL:
            urls.append(text[entity.offset:entity.offset + entity.length])
        elif entity.type == MessageEntity.TEXT_LINK:
            urls.append(entity.url)
    
    text_urls = re.findall(r'https?://[^\s<>"{}|\\^`\[\]]+', text)
    urls.extend(text_urls)
    
    return list(dict.fromkeys(urls))  # Unique, pÄƒstreazÄƒ ordinea


def filter_article_urls(urls: list) -> list:
    """FiltreazÄƒ doar URL-uri cÄƒtre articole."""
    ignore_domains = ['t.me', 'telegram.me', 'twitter.com', 'x.com', 
                      'facebook.com', 'instagram.com', 'tiktok.com', 'youtube.com', 'youtu.be']
    
    article_urls = []
    for url in urls:
        try:
            domain = urlparse(url).netloc.lower()
            if not any(ignore in domain for ignore in ignore_domains):
                article_urls.append(url)
        except:
            pass
    return article_urls


def format_summary_html(summary: str, url: str = None) -> str:
    """FormateazÄƒ rezumatul cu HTML."""
    summary = summary.replace("**", "").replace("*", "").replace("__", "")
    summary = summary.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
    
    # SeparÄƒ emoji
    emoji_part = ""
    text_part = summary
    if len(summary) > 0 and not summary[0].isalnum() and summary[0] not in '([{':
        i = 0
        while i < len(summary) and not summary[i].isalnum():
            i += 1
        emoji_part = summary[:i].rstrip()
        text_part = summary[i:].lstrip()
    
    # GÄƒseÈ™te cuvÃ¢ntul marcat
    link_word = None
    link_word_match = re.search(r'\{+([^}]+)\}+', text_part)
    if link_word_match:
        link_word = link_word_match.group(1)
        text_part = text_part[:link_word_match.start()] + link_word + text_part[link_word_match.end():]
    
    # ProceseazÄƒ paragrafe
    paragraphs = re.split(r'\n\s*\n|\n', text_part)
    paragraphs = [p.strip() for p in paragraphs if p.strip()]
    
    formatted_paragraphs = []
    for para_idx, paragraph in enumerate(paragraphs):
        words = paragraph.split()
        result_words = []
        
        for word_idx, word in enumerate(words):
            is_link_word = link_word and link_word in word
            
            if word_idx < 3:
                if is_link_word and url:
                    word_with_link = word.replace(link_word, f'<a href="{url}">{link_word}</a>')
                    if word_idx == 0:
                        result_words.append(f"<b>{word_with_link}")
                    elif word_idx == 2:
                        result_words.append(f"{word_with_link}</b>")
                    else:
                        result_words.append(word_with_link)
                    link_word = None
                else:
                    if word_idx == 0:
                        result_words.append(f"<b>{word}")
                    elif word_idx == 2:
                        result_words.append(f"{word}</b>")
                    else:
                        result_words.append(word)
            else:
                if is_link_word and url:
                    result_words.append(word.replace(link_word, f'<a href="{url}">{link_word}</a>'))
                    link_word = None
                else:
                    result_words.append(word)
        
        if len(words) > 0 and len(words) < 3:
            result_words[-1] = result_words[-1] + "</b>"
        
        formatted_para = " ".join(result_words)
        if para_idx > 0:
            formatted_para = "(...) " + formatted_para
        formatted_paragraphs.append(formatted_para)
    
    formatted_text = "\n\n".join(formatted_paragraphs)
    return f"{emoji_part} {formatted_text}" if emoji_part else formatted_text


def fetch_article_content(url: str) -> str | None:
    """DescarcÄƒ È™i extrage conÈ›inutul unui articol."""
    try:
        # Metoda 1: Trafilatura standard
        downloaded = trafilatura.fetch_url(url)
        if downloaded:
            content = trafilatura.extract(downloaded, include_comments=False, include_tables=False, no_fallback=False)
            if content and len(content) > 100:
                return content
        
        # Metoda 2: Fallback Jina AI - pentru ORICE site care eÈ™ueazÄƒ
        logger.info(f"Trafilatura eÈ™uat, Ã®ncerc Jina AI pentru: {url[:60]}")
        try:
            import httpx
            jina_url = f"https://r.jina.ai/{url}"
            response = httpx.get(jina_url, timeout=20.0, follow_redirects=True)
            if response.status_code == 200:
                content = response.text
                # CurÄƒÈ›Äƒ markdown headers È™i formatare excesivÄƒ
                content = re.sub(r'^#+\s+', '', content, flags=re.MULTILINE)
                content = re.sub(r'\n{3,}', '\n\n', content)
                if len(content) > 200:
                    logger.info(f"âœ“ Jina AI SUCCESS: {len(content)} caractere")
                    return content
                else:
                    logger.warning(f"Jina AI: conÈ›inut prea scurt ({len(content)} char)")
            else:
                logger.warning(f"Jina AI HTTP {response.status_code}")
        except Exception as e:
            logger.warning(f"Jina AI eÈ™uat: {type(e).__name__}: {str(e)[:50]}")
        
    except Exception as e:
        logger.error(f"Eroare extragere: {e}")
    
    return None


def generate_summary(content: str, url: str = None, length_type: str = "lung") -> tuple:
    """GenereazÄƒ rezumat. ReturneazÄƒ (rezumat, eroare)."""
    try:
        prompt_template = get_prompt(length_type, has_url=bool(url))
        prompt = prompt_template.format(content=content[:15000])
        
        message = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=1500,
            messages=[{"role": "user", "content": prompt}]
        )
        
        raw_summary = message.content[0].text
        formatted = format_summary_html(raw_summary, url)
        return formatted, None
        
    except anthropic.AuthenticationError:
        return None, "Cheie API invalidÄƒ"
    except anthropic.RateLimitError:
        return None, "Prea multe cereri"
    except anthropic.APIError as e:
        return None, f"Eroare API: {str(e)[:100]}"
    except Exception as e:
        return None, f"{type(e).__name__}: {str(e)[:100]}"


async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handler pentru /start."""
    welcome = (
        "ğŸ‘‹ Salut! Sunt botul pentru rezumate de È™tiri.\n\n"
        "ğŸ“ <b>Comenzi:</b>\n"
        "â€¢ <code>/scurt link</code> â†’ 250-300 caractere\n"
        "â€¢ <code>/mediu link</code> â†’ 500-600 caractere\n"
        "â€¢ <code>/lung link</code> â†’ 850-950 caractere\n"
        "â€¢ Link fÄƒrÄƒ comandÄƒ â†’ lung (default)\n\n"
        "ğŸ“¦ <b>Batch:</b> Trimite pÃ¢nÄƒ la 7 linkuri (pe linii separate) â†’ rezumate scurte\n\n"
        "ğŸš€ Trimite primul link!"
    )
    await update.message.reply_text(welcome, parse_mode=ParseMode.HTML)


async def process_single_article(url: str, length_type: str) -> str:
    """ProceseazÄƒ un singur articol È™i returneazÄƒ rezumatul."""
    content = fetch_article_content(url)
    if not content:
        return f"âŒ Nu am putut extrage: {url[:50]}..."
    
    summary, error = generate_summary(content, url, length_type)
    if not summary:
        return f"âŒ Eroare pentru {url[:50]}...: {error}"
    
    return summary


def get_relevant_emoji(text: str) -> str:
    """DeterminÄƒ emoji-ul relevant pe baza conÈ›inutului textului."""
    text_lower = text.lower()
    
    # PoliticÄƒ / Guvern
    if any(word in text_lower for word in ['parlament', 'guvern', 'ministru', 'deputat', 'legislativ', 'politic', 'alegeri', 'vot', 'lege', 'preÅŸedinte', 'premier']):
        return 'ğŸ›ï¸'
    
    # Moldova
    if any(word in text_lower for word in ['moldova', 'chiÈ™inÄƒu', 'chisinau', 'maia sandu', 'pas ']):
        return 'ğŸ‡²ğŸ‡©'
    
    # RomÃ¢nia
    if any(word in text_lower for word in ['romÃ¢nia', 'romania', 'bucureÅŸti', 'bucuresti', 'iohannis']):
        return 'ğŸ‡·ğŸ‡´'
    
    # UE
    if any(word in text_lower for word in ['uniunea europeanÄƒ', 'uniunea europeana', 'bruxelles', 'comisia europeanÄƒ', 'ue ']):
        return 'ğŸ‡ªğŸ‡º'
    
    # Rusia
    if any(word in text_lower for word in ['rusia', 'kremlin', 'moscova', 'putin']):
        return 'ğŸ‡·ğŸ‡º'
    
    # SUA
    if any(word in text_lower for word in ['sua', 'statele unite', 'washington', 'america', 'trump', 'biden']):
        return 'ğŸ‡ºğŸ‡¸'
    
    # FranÈ›a
    if any(word in text_lower for word in ['franÅ£a', 'franta', 'paris', 'macron', 'francez']):
        return 'ğŸ‡«ğŸ‡·'
    
    # RÄƒzboi / Conflict / ArmatÄƒ
    if any(word in text_lower for word in ['rÄƒzboi', 'razboi', 'conflict', 'militar', 'armatÄƒ', 'armata', 'atac', 'arme', 'soldaÅ£', 'soldat']):
        return 'âš”ï¸'
    
    # JustiÈ›ie / Lege
    if any(word in text_lower for word in ['judecÄƒtor', 'judecator', 'tribunal', 'condamnat', 'sentinÅ£Äƒ', 'sentinta', 'proces', 'procuror', 'avocat', 'instanÅ£Äƒ', 'instanta']):
        return 'âš–ï¸'
    
    # Economie / Bani
    if any(word in text_lower for word in ['economie', 'bancÄƒ', 'banca', 'bani', 'preÅ£', 'pret', 'dolar', 'euro', 'inflaÈ›ie', 'inflatie', 'salariu', 'buget', 'fiscal']):
        return 'ğŸ’°'
    
    # Tehnologie / Digital
    if any(word in text_lower for word in ['tehnologie', 'tehnologic', 'digital', 'internet', 'computer', 'software', 'ai ', 'inteligenÈ›Äƒ artificialÄƒ', 'crypto', 'blockchain']):
        return 'ğŸ’»'
    
    # SÄƒnÄƒtate / Medical
    if any(word in text_lower for word in ['sÄƒnÄƒtate', 'sanatate', 'medical', 'spital', 'doctor', 'pacient', 'boalÄƒ', 'boala', 'virus', 'vaccin', 'tratament']):
        return 'ğŸ¥'
    
    # Sport
    if any(word in text_lower for word in ['fotbal', 'meci', 'echipÄƒ', 'echipa', 'campionat', 'jucÄƒtor', 'jucator', 'sport', 'olimpic', 'antrenor']):
        return 'âš½'
    
    # Mediu / NaturÄƒ
    if any(word in text_lower for word in ['mediu', 'climÄƒ', 'clima', 'poluare', 'ecologic', 'naturÄƒ', 'natura', 'pÄƒdure', 'padure']):
        return 'ğŸŒ'
    
    # EducaÈ›ie
    if any(word in text_lower for word in ['educaÅ£ie', 'educatie', 'ÅŸcoalÄƒ', 'scoala', 'universitate', 'student', 'profesor', 'elev']):
        return 'ğŸ“š'
    
    # Transport / Auto
    if any(word in text_lower for word in ['maÅŸinÄƒ', 'masina', 'auto', 'trafic', 'ÅŸofer', 'sofer', 'drum', 'accident']):
        return 'ğŸš—'
    
    # Energie
    if any(word in text_lower for word in ['energie', 'electric', 'gaz', 'petrol', 'combustibil', 'centralÄƒ', 'centrala']):
        return 'âš¡'
    
    # Default - È™tiri generale
    return 'ğŸ“°'


def ensure_emoji_in_summaries(summaries: list) -> list:
    """AsigurÄƒ cÄƒ fiecare rezumat are emoji la Ã®nceput (adaugÄƒ emoji relevant dacÄƒ lipseÈ™te)."""
    fixed_summaries = []
    
    for summary in summaries:
        # Skip mesaje de eroare
        if summary.startswith('âŒ'):
            fixed_summaries.append(summary)
            continue
        
        # VerificÄƒ dacÄƒ conÈ›ine emoji ORIUNDE la Ã®nceput (ignorÄƒ HTML tags)
        # EliminÄƒ temporar HTML tags pentru a verifica emoji
        text_without_html = re.sub(r'<[^>]+>', '', summary[:50])  # Check primele 50 char fÄƒrÄƒ HTML
        
        has_emoji = False
        # VerificÄƒ dacÄƒ PRIMELE caractere non-whitespace conÈ›in emoji
        match = re.search(r'^[\s]*[\U0001F000-\U0001FFFF\u2600-\u26FF\u2700-\u27BF\U0001F900-\U0001F9FF\U0001F1E0-\U0001F1FF]', text_without_html)
        if match:
            has_emoji = True
        
        # DacÄƒ nu are emoji, determinÄƒ unul relevant È™i adaugÄƒ-l
        if not has_emoji:
            relevant_emoji = get_relevant_emoji(summary)
            logger.info(f"Adding relevant emoji {relevant_emoji} to: {summary[:50]}...")
            fixed_summaries.append(f"{relevant_emoji} {summary}")
        else:
            fixed_summaries.append(summary)
    
    return fixed_summaries

def remove_duplicate_emojis_in_batch(summaries: list) -> list:
    """EliminÄƒ TOATE emoji-urile duplicate dintr-o listÄƒ de rezumate (pÄƒstreazÄƒ doar prima apariÈ›ie)."""
    if not summaries or len(summaries) <= 1:
        return summaries
    
    cleaned_summaries = []
    seen_emojis = set()  # Track TOATE emoji-urile vÄƒzute
    
    for idx, summary in enumerate(summaries):
        # Skip mesaje de eroare (care Ã®ncep cu âŒ)
        if summary.startswith('âŒ'):
            cleaned_summaries.append(summary)
            continue
        
        # Extrage emoji-ul: orice caractere non-word, non-space, non-HTML la Ã®nceput
        current_emoji = None
        
        # Match orice caractere non-ASCII la Ã®nceput pÃ¢nÄƒ la primul caracter alfanumeric, spaÈ›iu sau <
        match = re.match(r'^([\U0001F000-\U0001FFFF\u2600-\u26FF\u2700-\u27BF\U0001F900-\U0001F9FF\U0001F1E0-\U0001F1FF]+)\s*', summary)
        if match:
            current_emoji = match.group(1)
        
        logger.info(f"Batch #{idx}: emoji='{current_emoji}', seen={seen_emojis}")
        
        # VerificÄƒ dacÄƒ emoji-ul a mai apÄƒrut ORIUNDE Ã®n batch (nu doar consecutiv)
        if current_emoji and current_emoji in seen_emojis:
            logger.info(f"  âœ‚ï¸ Eliminating duplicate (seen before): {current_emoji}")
            # EliminÄƒ emoji-ul
            cleaned_summary = re.sub(r'^[\U0001F000-\U0001FFFF\u2600-\u26FF\u2700-\u27BF\U0001F900-\U0001F9FF\U0001F1E0-\U0001F1FF]+\s*', '', summary, count=1)
            cleaned_summaries.append(cleaned_summary)
        else:
            cleaned_summaries.append(summary)
        
        # AdaugÄƒ emoji-ul Ã®n set-ul de "vÄƒzute"
        if current_emoji:
            seen_emojis.add(current_emoji)
    
    return cleaned_summaries


async def handle_length_command(update: Update, context: ContextTypes.DEFAULT_TYPE, length_type: str):
    """Handler comun pentru comenzile /scurt, /mediu, /lung."""
    text = update.message.text or ""
    
    # Extrage linkurile din mesaj (dupÄƒ comandÄƒ)
    urls = re.findall(r'https?://[^\s<>"{}|\\^`\[\]]+', text)
    article_urls = filter_article_urls(urls)
    
    if not article_urls:
        await update.message.reply_text(f"âŒ FoloseÈ™te: /{length_type} https://link-articol.com")
        return
    
    processing_msg = await update.message.reply_text("â³ Procesez...")
    
    # Un singur link
    if len(article_urls) == 1:
        summary = await process_single_article(article_urls[0], length_type)
        await processing_msg.edit_text(summary, parse_mode=ParseMode.HTML)
    else:
        # Batch - max 7, foloseÈ™te tipul specificat
        urls_to_process = article_urls[:MAX_BATCH_LINKS]
        summaries = []
        
        for i, url in enumerate(urls_to_process):
            await processing_msg.edit_text(f"â³ Procesez {i+1}/{len(urls_to_process)}...")
            summary = await process_single_article(url, length_type)
            summaries.append(summary)
        
        # AsigurÄƒ cÄƒ toate rezumatele au emoji (adaugÄƒ ğŸ“° dacÄƒ lipseÈ™te)
        summaries = ensure_emoji_in_summaries(summaries)
        
        # EliminÄƒ emoji-uri duplicate
        summaries = remove_duplicate_emojis_in_batch(summaries)
        
        final_text = "\n\n".join(summaries)
        
        # Telegram are limitÄƒ de 4096 caractere
        if len(final_text) > 4000:
            final_text = final_text[:4000] + "\n\nâš ï¸ Textul a fost trunchiat."
        
        await processing_msg.edit_text(final_text, parse_mode=ParseMode.HTML)


async def scurt_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await handle_length_command(update, context, "scurt")

async def mediu_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await handle_length_command(update, context, "mediu")

async def lung_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await handle_length_command(update, context, "lung")


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handler pentru mesaje fÄƒrÄƒ comandÄƒ."""
    text = update.message.text or update.message.caption or ""
    
    if not text.strip():
        await update.message.reply_text("âŒ Mesajul e gol.")
        return
    
    all_urls = extract_urls_from_entities(update.message)
    article_urls = filter_article_urls(all_urls)
    
    if not article_urls:
        # Text fÄƒrÄƒ URL - rezumat lung din text
        cleaned_text = clean_telegram_footer(text)
        if len(cleaned_text) < 50:
            await update.message.reply_text("âŒ Textul e prea scurt.")
            return
        
        processing_msg = await update.message.reply_text("â³ Procesez textul...")
        summary, error = generate_summary(cleaned_text, url=None, length_type="lung")
        
        if not summary:
            await processing_msg.edit_text(f"âŒ Eroare: {error}")
            return
        
        await processing_msg.edit_text(summary, parse_mode=ParseMode.HTML)
        return
    
    processing_msg = await update.message.reply_text("â³ Procesez...")
    
    # Un singur link - rezumat LUNG (default)
    if len(article_urls) == 1:
        summary = await process_single_article(article_urls[0], "lung")
        await processing_msg.edit_text(summary, parse_mode=ParseMode.HTML)
    else:
        # Batch - max 7, rezumate SCURTE
        urls_to_process = article_urls[:MAX_BATCH_LINKS]
        summaries = []
        
        for i, url in enumerate(urls_to_process):
            await processing_msg.edit_text(f"â³ Procesez {i+1}/{len(urls_to_process)}...")
            summary = await process_single_article(url, "scurt")
            summaries.append(summary)
        
        # AsigurÄƒ cÄƒ toate rezumatele au emoji (adaugÄƒ ğŸ“° dacÄƒ lipseÈ™te)
        summaries = ensure_emoji_in_summaries(summaries)
        
        # EliminÄƒ emoji-uri duplicate
        summaries = remove_duplicate_emojis_in_batch(summaries)
        
        final_text = "\n\n".join(summaries)
        
        if len(final_text) > 4000:
            final_text = final_text[:4000] + "\n\nâš ï¸ Textul a fost trunchiat."
        
        if len(article_urls) > MAX_BATCH_LINKS:
            final_text += f"\n\nâš ï¸ Am procesat doar primele {MAX_BATCH_LINKS} linkuri."
        
        await processing_msg.edit_text(final_text, parse_mode=ParseMode.HTML)


def main():
    """PorneÈ™te botul."""
    if not TELEGRAM_TOKEN:
        raise ValueError("TELEGRAM_TOKEN nu e setat!")
    if not ANTHROPIC_API_KEY:
        raise ValueError("ANTHROPIC_API_KEY nu e setat!")
    
    application = Application.builder().token(TELEGRAM_TOKEN).build()
    
    # Comenzi
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("scurt", scurt_command))
    application.add_handler(CommandHandler("mediu", mediu_command))
    application.add_handler(CommandHandler("lung", lung_command))
    
    # Mesaje text
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(MessageHandler(filters.FORWARDED, handle_message))
    
    logger.info("Botul porneÈ™te...")
    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    main()
